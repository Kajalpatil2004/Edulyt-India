{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0201d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed93091",
   "metadata": {},
   "source": [
    "# 1.Upload the data in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0d917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['New_Card', 'District', 'Loan', 'New_Client', 'New_Disposition', 'New_Account', 'New_Transaction', 'Order']\n",
    "tables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a484e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in table_names:\n",
    "    try:\n",
    "        df=pd.read_excel(\"Main_Data.xlsx\",sheet_name=table_name)\n",
    "        tables[table_name]=df\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing {table_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a7410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   card_id  disp_id     type  issued\n",
      "0     1005     9285  CLASSIC  931107\n",
      "1      104      588  CLASSIC  940119\n"
     ]
    }
   ],
   "source": [
    "New_Card=tables['New_Card']\n",
    "print(New_Card.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c4ba6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A1           A2               A3       A4  A5  A6  A7  A8  A9    A10  \\\n",
      "0   1  Hl.m. Praha           Prague  1204953   0   0   0   1   1  100.0   \n",
      "1   2      Benesov  central Bohemia    88884  80  26   6   2   5   46.7   \n",
      "\n",
      "     A11   A12   A13  A14    A15    A16  \n",
      "0  12541  0.29  0.43  167  85677  99107  \n",
      "1   8507  1.67  1.85  132   2159   2674  \n"
     ]
    }
   ],
   "source": [
    "District=tables['District']\n",
    "print(District.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30bc6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_id  account_id    date  amount  duration  payments status\n",
      "0     5314        1787  930705   96396        12      8033      B\n",
      "1     5316        1801  930711  165960        36      4610      A\n"
     ]
    }
   ],
   "source": [
    "Loan=tables['Loan']\n",
    "print(Loan.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fad3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  client_id  birth_number  district_id  gender  age   age_levels\n",
      "0           1          1        701213           18  FEMALE   29        ADULT\n",
      "1           2          2        450204            1    MALE   54  MIDDLE AGED\n"
     ]
    }
   ],
   "source": [
    "New_Client=tables['New_Client']\n",
    "print(New_Client.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc63ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   disp_id  client_id  account_id   type\n",
      "0        1          1           1  OWNER\n",
      "1        2          2           2  OWNER\n"
     ]
    }
   ],
   "source": [
    "New_Disposition=tables['New_Disposition']\n",
    "print(New_Disposition.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ff6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account_id  district_id         frequency\n",
      "0         576           55  MONTHLY ISSUANCE\n",
      "1        3818           74  MONTHLY ISSUANCE\n"
     ]
    }
   ],
   "source": [
    "New_Account=tables['New_Account']\n",
    "print(New_Account.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0af9fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  account_id bank_to  account_to  amount k_symbol\n",
      "0     29401           1      YZ    87144583  2452.0     SIPO\n",
      "1     29402           2      ST    89597016  3372.7     UVER\n"
     ]
    }
   ],
   "source": [
    "Order=tables['Order']\n",
    "print(Order.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5625bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  account_id    date    type       operation  amount  balance  \\\n",
      "0           1        2378  930101  CREDIT  CREDIT IN CASH   700.0    700.0   \n",
      "1           2         576  930101  CREDIT  CREDIT IN CASH   900.0    900.0   \n",
      "\n",
      "  k_symbol  \n",
      "0      NaN  \n",
      "1      NaN  \n"
     ]
    }
   ],
   "source": [
    "New_Transaction=tables['New_Transaction']\n",
    "print(New_Transaction.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8c713",
   "metadata": {},
   "source": [
    "# 2.Find the joining factors between different tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c77be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined DataFrame:\n",
      "        Unnamed: 0  client_id  birth_number  district_id  gender  age  \\\n",
      "0                1          1        701213           18  FEMALE   29   \n",
      "1                1          1        701213           18  FEMALE   29   \n",
      "2                1          1        701213           18  FEMALE   29   \n",
      "3                1          1        701213           18  FEMALE   29   \n",
      "4                1          1        701213           18  FEMALE   29   \n",
      "...            ...        ...           ...          ...     ...  ...   \n",
      "648556        5198      11701        490414            9    MALE   50   \n",
      "648557        5198      11701        490414            9    MALE   50   \n",
      "648558        5198      11701        490414            9    MALE   50   \n",
      "648559        5198      11701        490414            9    MALE   50   \n",
      "648560        5198      11701        490414            9    MALE   50   \n",
      "\n",
      "         age_levels  account_id         frequency  \n",
      "0             ADULT       10973   WEEKLY ISSUANCE  \n",
      "1             ADULT        3287  MONTHLY ISSUANCE  \n",
      "2             ADULT        2987  MONTHLY ISSUANCE  \n",
      "3             ADULT        2479  MONTHLY ISSUANCE  \n",
      "4             ADULT        3003  MONTHLY ISSUANCE  \n",
      "...             ...         ...               ...  \n",
      "648556  MIDDLE AGED        4091  MONTHLY ISSUANCE  \n",
      "648557  MIDDLE AGED        1342  MONTHLY ISSUANCE  \n",
      "648558  MIDDLE AGED        1727  MONTHLY ISSUANCE  \n",
      "648559  MIDDLE AGED        3963  MONTHLY ISSUANCE  \n",
      "648560  MIDDLE AGED         934  MONTHLY ISSUANCE  \n",
      "\n",
      "[648561 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "common_columns = set(tables['New_Client'].columns).intersection(set(tables['New_Account'].columns))\n",
    "\n",
    "# Perform the join if there are common columns\n",
    "if common_columns:\n",
    "    joined_df = pd.merge(tables['New_Client'], tables['New_Account'], on=list(common_columns), how='inner')\n",
    "    print(\"Joined DataFrame:\")\n",
    "    print(joined_df)\n",
    "else:\n",
    "    print(\"Unable to perform the join due to missing common columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e11d43",
   "metadata": {},
   "source": [
    "# 3. Is there any need for data cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68e3f0",
   "metadata": {},
   "source": [
    "# Check for missing values in each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7e1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: New_Card-Missing Values:0\n",
      "Table: District-Missing Values:0\n",
      "Table: Loan-Missing Values:0\n",
      "Table: New_Client-Missing Values:0\n",
      "Table: New_Disposition-Missing Values:0\n",
      "Table: New_Account-Missing Values:0\n",
      "Table: New_Transaction-Missing Values:657309\n",
      "Table: Order-Missing Values:1379\n"
     ]
    }
   ],
   "source": [
    "for table_name,df in tables.items():\n",
    "    missing_values=df.isnull().sum().sum()\n",
    "    print(f\"Table: {table_name}-Missing Values:{missing_values}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927b0d4",
   "metadata": {},
   "source": [
    "# Check for duplicate values in each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54fe8236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: New_Card - Duplicate Rows: 0\n",
      "Table: District - Duplicate Rows: 0\n",
      "Table: Loan - Duplicate Rows: 0\n",
      "Table: New_Client - Duplicate Rows: 0\n",
      "Table: New_Disposition - Duplicate Rows: 0\n",
      "Table: New_Account - Duplicate Rows: 0\n",
      "Table: New_Transaction - Duplicate Rows: 0\n",
      "Table: Order - Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "for table_name, df in tables.items():\n",
    "     duplicates = df.duplicated().sum()\n",
    "     print(f\"Table: {table_name} - Duplicate Rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b2a4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows were deleted from New_Card.\n",
      "No rows were deleted from District.\n",
      "No rows were deleted from Loan.\n",
      "No rows were deleted from New_Client.\n",
      "No rows were deleted from New_Disposition.\n",
      "No rows were deleted from New_Account.\n",
      "No rows were deleted from New_Transaction.\n",
      "No rows were deleted from Order.\n"
     ]
    }
   ],
   "source": [
    "for table_name, df in tables.items():\n",
    "    before_drop = df.shape[0]  # Number of rows before dropping\n",
    "    df.dropna(inplace=True)\n",
    "    after_drop = df.shape[0]  # Number of rows after dropping\n",
    "\n",
    "    if before_drop > after_drop:\n",
    "        print(f\"Rows have been deleted from {table_name}.\")\n",
    "    else:\n",
    "        print(f\"No rows were deleted from {table_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
